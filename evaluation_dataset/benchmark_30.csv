question,choice1,choice2,choice3,choice4,answer
고성능 계산(HPC)의 주요 목적은 무엇인가요?,대규모 계산을 빠르게 수행하기 위함,사용자 인터페이스를 예쁘게 만들기 위함,웹 페이지 로딩 속도를 느리게 하기 위함,이메일 전송 속도를 낮추기 위함,1
병렬 컴퓨팅(parallel computing)을 가장 잘 설명한 것은 무엇인가요?,하나의 프로세서가 모든 작업을 순차적으로 처리하는 방식,여러 프로세서가 동시에 작업을 나누어 처리하는 방식,프로세서가 일을 하지 않고 대기하는 방식,한 번에 하나의 비트만 연산하는 방식,2
GPU를 사용하는 주된 이유는 무엇인가요?,네트워크 지연 시간을 줄이기 위해,대규모 병렬 연산을 빠르게 처리하기 위해,하드디스크 용량을 늘리기 위해,운영체제 부팅 속도를 늦추기 위해,2
CFD(전산유체역학)의 주요 목적은 무엇인가요?,유체의 거동을 수치적으로 모델링하고 시뮬레이션하기 위함,데이터베이스 인덱스를 최적화하기 위함,이미지 압축 알고리즘을 설계하기 위함,웹 서버의 로그를 분석하기 위함,1
다음 중 메모리 병목(memory bottleneck)을 가장 잘 설명한 것은 무엇인가요?,저장 장치의 용량이 너무 큰 현상,메모리 대역폭이나 용량이 부족해 계산 속도가 제한되는 현상,GPU 코어 수가 너무 많은 현상,CPU 클럭이 너무 빠른 현상,2
스케일 업(scale-up) 아키텍처를 설명한 것은 무엇인가요?,여러 대의 작은 서버를 추가로 투입하는 방식,하나의 서버에 더 강력한 CPU·메모리·GPU를 추가하는 방식,네트워크 케이블을 여러 개 묶는 방식,스토리지 디스크를 외부로 옮기는 방식,2
LLM 파인튜닝(fine-tuning)의 주된 목적은 무엇인가요?,모델의 파라미터 수를 줄여서 항상 성능을 낮추기 위해,특정 도메인이나 태스크에 맞게 모델의 출력을 조정하기 위해,모델의 사전 학습 데이터를 전부 삭제하기 위해,모델을 다른 프로그래밍 언어로 변환하기 위해,2
SFT(Supervised Fine-Tuning)를 가장 잘 설명한 것은 무엇인가요?,레이블이 없는 데이터를 사용하는 비지도 학습,강화학습으로 보상을 최대화하는 과정,입력과 정답이 쌍으로 주어진 데이터를 이용해 지도학습하는 과정,모델 구조를 자동으로 탐색하는 과정,3
LoRA(Low-Rank Adaptation)의 장점으로 알맞은 것은 무엇인가요?,기존 가중치를 모두 삭제하고 새로 학습한다,추가 파라미터 없이도 정확도가 항상 향상된다,소량의 추가 파라미터만 학습하여 메모리와 연산 비용을 줄일 수 있다,학습 데이터를 사용하지 않고도 모델을 튜닝할 수 있다,3
토크나이저(tokenizer)의 역할로 알맞은 것은 무엇인가요?,모델의 파라미터 수를 계산하는 역할,텍스트를 숫자 토큰 시퀀스로 변환하는 역할,GPU 클럭 속도를 조절하는 역할,네트워크 패킷을 암호화하는 역할,2
배치 크기(batch size)를 키웠을 때 일반적으로 기대할 수 있는 효과는 무엇인가요?,한 번의 업데이트마다 더 많은 샘플을 사용해 학습 안정성이 높아질 수 있다,항상 학습 속도가 느려진다,항상 일반화 성능이 나빠진다,모델 파라미터 수가 자동으로 줄어든다,1
학습률(learning rate)이 너무 클 때 주로 나타나는 문제는 무엇인가요?,손실 값이 매우 천천히 감소한다,손실 값이 발산하거나 진동하면서 수렴하지 못한다,모델 파라미터 수가 줄어든다,학습 데이터 양이 자동으로 증가한다,2
검증 데이터셋(validation set)의 주된 목적은 무엇인가요?,모델 학습에 직접 사용되는 데이터를 늘리기 위해,테스트 데이터와 완전히 동일한 분포를 만들기 위해,학습 과정 중 모델의 성능을 모니터링하고 과적합 여부를 확인하기 위해,데이터를 무작위로 삭제하기 위해,3
과적합(overfitting)을 가장 잘 설명한 것은 무엇인가요?,모델이 학습 데이터와 테스트 데이터에서 모두 성능이 낮은 상태,모델이 학습 데이터에는 매우 잘 맞지만 새로운 데이터에는 성능이 떨어지는 상태,모델이 파라미터 업데이트를 전혀 하지 않는 상태,학습 데이터가 전혀 없는 상태,2
다음 중 정규화(regularization) 기법의 예로 볼 수 있는 것은 무엇인가요?,배치 크기를 크게 설정하는 것,학습률을 0으로 만드는 것,Dropout을 사용하여 일부 뉴런을 확률적으로 비활성화하는 것,파라미터를 모두 정수로 반올림하는 것,3
KMMLU 벤치마크와 가장 관련이 깊은 설명은 무엇인가요?,대규모 이미지 분류용 데이터셋,한국어 멀티태스크 언어 이해 성능을 평가하는 벤치마크,음성 인식 시스템의 정확도를 평가하는 벤치마크,강화학습 환경에서 보상을 측정하는 지표,2
MLOps/LLMOps에서 '모니터링(monitoring)'의 주요 목적은 무엇인가요?,GPU 온도를 일정하게 유지하기 위해,"모델의 예측 성능, 지연 시간, 이상 행동 등을 운영 환경에서 지속적으로 관찰하기 위해",사용자 수를 줄이기 위해,데이터를 무작위로 섞기 위해,2
파이썬에서 가상환경(virtual environment)을 만드는 대표적인 도구는 무엇인가요?,git,docker,venv,ssh,3
다음 중 딥러닝 프레임워크로 올바른 것은 무엇인가요?,NumPy,PyTorch,Pandas,Matplotlib,2
손실 함수(loss function)의 역할은 무엇인가요?,모델 구조를 자동으로 설계한다,모델 파라미터 수를 정한다,모델 예측과 정답 간의 차이를 수치적으로 측정한다,GPU 메모리 사용량을 줄인다,3
크로스 엔트로피(cross-entropy) 손실을 주로 사용하는 작업은 무엇인가요?,회귀(regression),군집화(clustering),분류(classification),차원 축소(dimensionality reduction),3
다음 중 옵티마이저(optimizer)가 아닌 것은 무엇인가요?,SGD,Adam,RMSProp,ReLU,4
레이블이 없는 데이터만 사용하는 학습 방법은 무엇인가요?,지도 학습(supervised learning),비지도 학습(unsupervised learning),강화 학습(reinforcement learning),전이 학습(transfer learning),2
모델의 파라미터 수가 많을수록 일반적으로 어떤 특성이 증가하나요?,표현력(Expressive power),디스크 용량,네트워크 지연 시간,운영체제 버전,1
학습 데이터에 심한 편향(bias)이 있을 경우 주로 어떤 문제가 발생하나요?,모델이 항상 무작위로 예측한다,특정 패턴이나 집단에 대해 불공정하거나 왜곡된 예측을 할 수 있다,모델 파라미터가 자동으로 감소한다,학습 시간이 0이 된다,2
Inference(추론) 단계에 대한 설명으로 올바른 것은 무엇인가요?,모델 파라미터를 업데이트하는 단계,학습 데이터를 수집하는 단계,학습이 끝난 모델을 사용해 새로운 입력에 대한 출력을 생성하는 단계,데이터를 전처리하는 단계,3
프롬프트 엔지니어링(prompt engineering)의 주요 목적은 무엇인가요?,모델 구조를 변경하기 위해,프롬프트를 설계해 LLM이 원하는 방식으로 응답하도록 유도하기 위해,GPU 수를 줄이기 위해,데이터셋 크기를 줄이기 위해,2
Top-k 샘플링에서 k 값이 의미하는 것은 무엇인가요?,사용할 GPU의 개수,허용되는 최대 시퀀스 길이,확률이 높은 상위 k개의 후보 토큰만 고려하는 것,데이터셋의 샘플 수,3
실험에서 랜덤 시드(seed)를 고정하는 주된 이유는 무엇인가요?,모델의 정확도를 항상 최대화하기 위해,코드 실행 속도를 높이기 위해,실험 결과를 재현(reproducibility) 가능하게 만들기 위해,GPU 메모리를 늘리기 위해,3
Docker와 같은 컨테이너 도구의 주요 이점은 무엇인가요?,하드웨어 성능을 자동으로 향상시킨다,코드와 실행 환경을 패키징하여 어디서든 동일한 환경에서 실행할 수 있게 한다,GPU를 항상 100% 사용하도록 만든다,데이터셋을 자동으로 생성해 준다,2
